# Runa Unit Testing Framework
# A comprehensive testing framework for Runa applications

import runa.time
import runa.io
import runa.format
import runa.system
import runa.console

# Test Result Status
Let TEST_PASS = "PASS"
Let TEST_FAIL = "FAIL"
Let TEST_ERROR = "ERROR"
Let TEST_SKIP = "SKIP"

# -----------------------------------------------------
# Test Configuration
# -----------------------------------------------------

Process called "create_test_config" that takes options:
    Let config = {
        "test_dir": "./tests",
        "report_format": "console",
        "report_file": null,
        "fail_fast": false,
        "timeout": 30,
        "parallelize": false,
        "verbose": true,
        "capture_output": true,
        "include_tags": [],
        "exclude_tags": [],
        "filter_pattern": null,
        "randomize": false,
        "seed": null,
        "color_output": true
    }
    
    # Apply custom options
    If options:
        For key in options:
            config[key] = options[key]
    
    Return config

# -----------------------------------------------------
# Test Suite
# -----------------------------------------------------

Process called "create_test_suite" that takes name, description:
    Let suite = {
        "name": name,
        "description": description || "",
        "tests": [],
        "before_all": null,
        "after_all": null,
        "before_each": null,
        "after_each": null,
        "config": create_test_config(),
        "stats": {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "errors": 0,
            "skipped": 0,
            "start_time": null,
            "end_time": null,
            "duration": 0
        }
    }
    
    # Method to add a test to the suite
    suite.add_test = function(test_name, test_fn, tags) {
        this.tests.push({
            "name": test_name,
            "function": test_fn,
            "tags": tags || [],
            "skip": false,
            "timeout": this.config.timeout,
            "result": null,
            "duration": 0,
            "output": "",
            "error": null
        })
        this.stats.total += 1
        Return this
    }
    
    # Method to skip a test
    suite.skip = function(test_name, test_fn, tags) {
        this.tests.push({
            "name": test_name,
            "function": test_fn,
            "tags": tags || [],
            "skip": true,
            "result": TEST_SKIP,
            "duration": 0,
            "output": "",
            "error": null
        })
        this.stats.total += 1
        this.stats.skipped += 1
        Return this
    }
    
    # Lifecycle hooks
    suite.before_all = function(fn) {
        this.before_all_fn = fn
        Return this
    }
    
    suite.after_all = function(fn) {
        this.after_all_fn = fn
        Return this
    }
    
    suite.before_each = function(fn) {
        this.before_each_fn = fn
        Return this
    }
    
    suite.after_each = function(fn) {
        this.after_each_fn = fn
        Return this
    }
    
    # Configure the test suite
    suite.configure = function(options) {
        For key in options:
            this.config[key] = options[key]
        Return this
    }
    
    # Run all tests in the suite
    suite.run = function() {
        Let start_time = runa.time.now()
        this.stats.start_time = start_time
        
        If this.config.verbose:
            Print("\n=== Running Test Suite: " + this.name + " ===")
            If this.description:
                Print(this.description + "\n")
        
        # Set up test environment
        Let capture_original_stdout = null
        If this.config.capture_output:
            capture_original_stdout = runa.console.capture_start()
        
        # Run before_all if defined
        If this.before_all_fn:
            Try:
                this.before_all_fn()
            Catch error:
                Print("Error in before_all: " + error)
                this.stats.errors += 1
        
        # Filter tests if requested
        Let tests_to_run = this.tests
        If this.config.filter_pattern:
            tests_to_run = this.tests.filter(test => 
                test.name.includes(this.config.filter_pattern))
        
        If this.config.include_tags.length > 0:
            tests_to_run = tests_to_run.filter(test => 
                test.tags.some(tag => this.config.include_tags.includes(tag)))
        
        If this.config.exclude_tags.length > 0:
            tests_to_run = tests_to_run.filter(test => 
                !test.tags.some(tag => this.config.exclude_tags.includes(tag)))
        
        # Randomize if requested
        If this.config.randomize:
            Let seed = this.config.seed || Math.floor(Math.random() * 10000)
            tests_to_run = randomize_array(tests_to_run, seed)
            If this.config.verbose:
                Print("Randomizing tests with seed: " + seed)
        
        # Run tests
        For test in tests_to_run:
            Let should_continue = run_test(test, this)
            If !should_continue && this.config.fail_fast:
                If this.config.verbose:
                    Print("Stopping test execution due to fail_fast option")
                Break
        
        # Run after_all if defined
        If this.after_all_fn:
            Try:
                this.after_all_fn()
            Catch error:
                Print("Error in after_all: " + error)
                this.stats.errors += 1
        
        # Restore stdout if captured
        If this.config.capture_output:
            runa.console.capture_end()
        
        # Calculate test duration
        Let end_time = runa.time.now()
        this.stats.end_time = end_time
        this.stats.duration = runa.time.difference_ms(start_time, end_time)
        
        # Print summary if verbose
        If this.config.verbose:
            print_test_summary(this)
        
        # Generate report
        If this.config.report_file:
            generate_test_report(this, this.config.report_format)
        
        Return this.stats
    }
    
    Return suite

# -----------------------------------------------------
# Test Execution
# -----------------------------------------------------

Process called "run_test" that takes test, suite:
    If test.skip:
        test.result = TEST_SKIP
        suite.stats.skipped += 1
        
        If suite.config.verbose:
            print_test_result(test, suite.config)
        
        Return true
    
    If suite.config.verbose:
        Print("Running test: " + test.name)
    
    # Reset test output
    test.output = ""
    
    # Run before_each if defined
    If suite.before_each_fn:
        Try:
            suite.before_each_fn()
        Catch error:
            test.error = "Error in before_each: " + error
            test.result = TEST_ERROR
            suite.stats.errors += 1
            
            If suite.config.verbose:
                print_test_result(test, suite.config)
            
            Return false
    
    # Capture output if requested
    Let capture_buffer = null
    If suite.config.capture_output:
        capture_buffer = runa.console.capture_start()
    
    # Run the test
    Let test_start_time = runa.time.now()
    
    Try:
        # Set timeout if supported
        Let timeout_id = null
        If runa.system.supports_timeout() && test.timeout > 0:
            timeout_id = runa.system.set_timeout(function() {
                throw new Error("Test timed out after " + test.timeout + " seconds")
            }, test.timeout * 1000)
        
        # Execute the test
        test.function()
        
        # Clear timeout if set
        If timeout_id:
            runa.system.clear_timeout(timeout_id)
        
        test.result = TEST_PASS
        suite.stats.passed += 1
    Catch error:
        test.error = error
        test.result = TEST_FAIL
        suite.stats.failed += 1
    
    # Calculate test duration
    test.duration = runa.time.difference_ms(test_start_time, runa.time.now())
    
    # Capture test output
    If suite.config.capture_output:
        test.output = runa.console.capture_end()
    
    # Run after_each if defined
    If suite.after_each_fn:
        Try:
            suite.after_each_fn()
        Catch error:
            If test.result == TEST_PASS:
                test.error = "Error in after_each: " + error
                test.result = TEST_ERROR
                suite.stats.errors += 1
                suite.stats.passed -= 1
    
    # Print test result if verbose
    If suite.config.verbose:
        print_test_result(test, suite.config)
    
    Return test.result == TEST_PASS || test.result == TEST_SKIP

# -----------------------------------------------------
# Assertions
# -----------------------------------------------------

Process called "assert_true" that takes actual, message:
    If !actual:
        Let error_msg = message || "Expected true but got " + actual
        throw new Error(error_msg)

Process called "assert_false" that takes actual, message:
    If actual:
        Let error_msg = message || "Expected false but got " + actual
        throw new Error(error_msg)

Process called "assert_equal" that takes actual, expected, message:
    If actual !== expected:
        Let error_msg = message || "Expected " + expected + " but got " + actual
        throw new Error(error_msg)

Process called "assert_not_equal" that takes actual, expected, message:
    If actual === expected:
        Let error_msg = message || "Expected " + actual + " to be different from " + expected
        throw new Error(error_msg)

Process called "assert_deep_equal" that takes actual, expected, message:
    Let result = compare_objects(actual, expected)
    If !result.equal:
        Let error_msg = message || "Objects not equal at path: " + result.path + 
                                 ". Expected " + result.expected + " but got " + result.actual
        throw new Error(error_msg)

Process called "assert_throws" that takes fn, error_type, message:
    Try:
        fn()
        Let error_msg = message || "Expected function to throw"
        throw new Error(error_msg)
    Catch error:
        If error_type && !(error instanceof error_type):
            Let error_msg = message || "Expected function to throw " + error_type.name + 
                                     " but got " + error.constructor.name
            throw new Error(error_msg)

Process called "assert_approx_equal" that takes actual, expected, epsilon, message:
    Let diff = Math.abs(actual - expected)
    Let eps = epsilon || 0.0001
    
    If diff > eps:
        Let error_msg = message || "Expected " + expected + " but got " + actual + 
                                 " (difference: " + diff + " > " + eps + ")"
        throw new Error(error_msg)

Process called "assert_contains" that takes collection, item, message:
    Let contains = false
    
    If Array.isArray(collection):
        contains = collection.includes(item)
    Else If typeof collection === "string":
        contains = collection.includes(item)
    Else If collection && typeof collection === "object":
        contains = item in collection
    
    If !contains:
        Let error_msg = message || "Expected collection to contain " + item
        throw new Error(error_msg)

Process called "assert_match" that takes string, pattern, message:
    If !pattern.test(string):
        Let error_msg = message || "Expected '" + string + "' to match " + pattern
        throw new Error(error_msg)

# -----------------------------------------------------
# Utility Functions
# -----------------------------------------------------

Process called "compare_objects" that takes actual, expected:
    # Handle simple types
    If typeof actual !== typeof expected:
        Return { equal: false, path: "", actual: typeof actual, expected: typeof expected }
    
    If typeof actual !== "object" || actual === null || expected === null:
        Return { equal: actual === expected, path: "", actual: actual, expected: expected }
    
    # Handle arrays
    If Array.isArray(actual) && Array.isArray(expected):
        If actual.length !== expected.length:
            Return { 
                equal: false, 
                path: ".length", 
                actual: actual.length, 
                expected: expected.length 
            }
        
        For i in range(0, actual.length):
            Let result = compare_objects(actual[i], expected[i])
            If !result.equal:
                Return { 
                    equal: false, 
                    path: "[" + i + "]" + result.path, 
                    actual: result.actual, 
                    expected: result.expected 
                }
        
        Return { equal: true }
    
    # Handle objects
    Let actual_keys = Object.keys(actual).sort()
    Let expected_keys = Object.keys(expected).sort()
    
    If actual_keys.length !== expected_keys.length:
        Return { 
            equal: false, 
            path: "", 
            actual: "object with keys [" + actual_keys.join(", ") + "]", 
            expected: "object with keys [" + expected_keys.join(", ") + "]" 
        }
    
    For i in range(0, actual_keys.length):
        Let key = actual_keys[i]
        If expected_keys[i] !== key:
            Return { 
                equal: false, 
                path: "", 
                actual: "key " + key, 
                expected: "key " + expected_keys[i] 
            }
        
        Let result = compare_objects(actual[key], expected[key])
        If !result.equal:
            Return { 
                equal: false, 
                path: "." + key + result.path, 
                actual: result.actual, 
                expected: result.expected 
            }
    
    Return { equal: true }

Process called "randomize_array" that takes array, seed:
    # Simple Fisher-Yates shuffle with a seeded random number generator
    Let seeded_random = create_seeded_random(seed)
    Let new_array = [...array]
    
    For i in range(new_array.length - 1, 0, -1):
        Let j = Math.floor(seeded_random() * (i + 1))
        Let temp = new_array[i]
        new_array[i] = new_array[j]
        new_array[j] = temp
    
    Return new_array

Process called "create_seeded_random" that takes seed:
    # Simple seeded random number generator
    Let state = seed || 1
    
    Return function() {
        state = (state * 16807) % 2147483647
        Return state / 2147483647
    }

# -----------------------------------------------------
# Reporting
# -----------------------------------------------------

Process called "print_test_result" that takes test, config:
    Let status_text = test.result
    Let color = "white"
    
    If config.color_output:
        If test.result == TEST_PASS:
            color = "green"
        Else If test.result == FAIL:
            color = "red"
        Else If test.result == TEST_ERROR:
            color = "yellow"
        Else If test.result == TEST_SKIP:
            color = "blue"
    
    Let duration_text = test.duration > 0 ? " (" + test.duration + "ms)" : ""
    Let message = status_text + ": " + test.name + duration_text
    
    If config.color_output:
        runa.console.color_print(message, color)
    Else:
        Print(message)
    
    If (test.result == TEST_FAIL || test.result == TEST_ERROR) && test.error:
        If config.color_output:
            runa.console.color_print("  Error: " + test.error, "red")
        Else:
            Print("  Error: " + test.error)
    
    If test.output && (test.result == TEST_FAIL || test.result == TEST_ERROR):
        Print("  Output:")
        Print("  " + test.output.replace(/\n/g, "\n  "))

Process called "print_test_summary" that takes suite:
    Let config = suite.config
    Let stats = suite.stats
    
    Print("\n=== Test Suite Summary: " + suite.name + " ===")
    Print("Total Tests: " + stats.total)
    
    If config.color_output:
        runa.console.color_print("Passed: " + stats.passed, "green")
        runa.console.color_print("Failed: " + stats.failed, "red")
        runa.console.color_print("Errors: " + stats.errors, "yellow")
        runa.console.color_print("Skipped: " + stats.skipped, "blue")
    Else:
        Print("Passed: " + stats.passed)
        Print("Failed: " + stats.failed)
        Print("Errors: " + stats.errors)
        Print("Skipped: " + stats.skipped)
    
    Print("Duration: " + (stats.duration / 1000).toFixed(2) + " seconds")
    
    # Calculate pass percentage
    Let run_tests = stats.total - stats.skipped
    Let pass_percentage = run_tests > 0 ? 
        Math.round((stats.passed / run_tests) * 100) : 0
    
    If config.color_output:
        Let color = pass_percentage == 100 ? "green" : 
                   pass_percentage >= 80 ? "yellow" : "red"
        runa.console.color_print("Pass Rate: " + pass_percentage + "%", color)
    Else:
        Print("Pass Rate: " + pass_percentage + "%")
    
    Print("===================================\n")

Process called "generate_test_report" that takes suite, format:
    Let report_file = suite.config.report_file
    
    If !report_file:
        Return
    
    Let content = ""
    
    If format == "json":
        Let report_data = {
            "name": suite.name,
            "description": suite.description,
            "stats": suite.stats,
            "tests": suite.tests.map(test => ({
                "name": test.name,
                "result": test.result,
                "duration": test.duration,
                "error": test.error,
                "tags": test.tags
            }))
        }
        content = JSON.stringify(report_data, null, 2)
    Else If format == "xml":
        content = generate_xml_report(suite)
    Else:
        # Plain text format
        content = generate_text_report(suite)
    
    # Write report to file
    Try:
        runa.io.write_file(report_file, content)
        Print("Test report saved to " + report_file)
    Catch error:
        Print("Error writing test report: " + error)

Process called "generate_xml_report" that takes suite:
    Let xml = '<?xml version="1.0" encoding="UTF-8"?>\n'
    xml += '<testsuites name="' + escape_xml(suite.name) + '" tests="' + suite.stats.total + 
           '" failures="' + suite.stats.failed + '" errors="' + suite.stats.errors + 
           '" skipped="' + suite.stats.skipped + '" time="' + (suite.stats.duration / 1000) + '">\n'
    
    xml += '  <testsuite name="' + escape_xml(suite.name) + '" tests="' + suite.stats.total + 
           '" failures="' + suite.stats.failed + '" errors="' + suite.stats.errors + 
           '" skipped="' + suite.stats.skipped + '" time="' + (suite.stats.duration / 1000) + '">\n'
    
    For test in suite.tests:
        xml += '    <testcase name="' + escape_xml(test.name) + '" time="' + (test.duration / 1000) + '"'
        If test.tags && test.tags.length > 0:
            xml += ' tags="' + escape_xml(test.tags.join(',')) + '"'
        
        If test.result == TEST_SKIP:
            xml += '>\n      <skipped/>\n    </testcase>\n'
        Else If test.result == TEST_FAIL:
            xml += '>\n      <failure message="' + escape_xml(test.error || "Test failed") + '"/>\n    </testcase>\n'
        Else If test.result == TEST_ERROR:
            xml += '>\n      <error message="' + escape_xml(test.error || "Test error") + '"/>\n    </testcase>\n'
        Else:
            xml += '/>\n'
    
    xml += '  </testsuite>\n'
    xml += '</testsuites>'
    
    Return xml

Process called "generate_text_report" that takes suite:
    Let text = "Test Suite: " + suite.name + "\n"
    text += "Description: " + suite.description + "\n"
    text += "Date: " + new Date(suite.stats.start_time).toISOString() + "\n\n"
    
    text += "Summary:\n"
    text += "  Total Tests: " + suite.stats.total + "\n"
    text += "  Passed: " + suite.stats.passed + "\n"
    text += "  Failed: " + suite.stats.failed + "\n"
    text += "  Errors: " + suite.stats.errors + "\n"
    text += "  Skipped: " + suite.stats.skipped + "\n"
    text += "  Duration: " + (suite.stats.duration / 1000).toFixed(2) + " seconds\n\n"
    
    text += "Test Results:\n"
    
    For test in suite.tests:
        text += "  " + test.result + ": " + test.name + 
                " (" + test.duration + "ms)\n"
        
        If test.tags && test.tags.length > 0:
            text += "    Tags: " + test.tags.join(", ") + "\n"
        
        If (test.result == TEST_FAIL || test.result == TEST_ERROR) && test.error:
            text += "    Error: " + test.error + "\n"
        
        If test.output && (test.result == TEST_FAIL || test.result == TEST_ERROR):
            text += "    Output:\n"
            Let output_lines = test.output.split("\n")
            For line in output_lines:
                text += "      " + line + "\n"
        
        text += "\n"
    
    Return text

Process called "escape_xml" that takes str:
    Return str.replace(/&/g, "&amp;")
             .replace(/</g, "&lt;")
             .replace(/>/g, "&gt;")
             .replace(/"/g, "&quot;")
             .replace(/'/g, "&apos;")

# -----------------------------------------------------
# Export Public API
# -----------------------------------------------------

export {
    # Test Suite Creation
    create_test_suite,
    create_test_config,
    
    # Assertions
    assert_true,
    assert_false,
    assert_equal,
    assert_not_equal,
    assert_deep_equal,
    assert_throws,
    assert_approx_equal,
    assert_contains,
    assert_match,
    
    # Constants
    TEST_PASS,
    TEST_FAIL,
    TEST_ERROR,
    TEST_SKIP
} 