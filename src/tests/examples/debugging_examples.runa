# Intelligent Debugging Examples
# This file demonstrates how to use Runa's intelligent debugging capabilities

import runa.debugging
import runa.ai.semantic_indexing
import runa.ai.knowledge_graph
import runa.ai.llm

# Example 1: Basic error diagnosis
Process called "diagnose_simple_error":
    # Create sample error for demonstration
    Let error_object = create_sample_error("division_by_zero", {
        "line": 42,
        "file": "calculator.runa",
        "function": "calculate_average",
        "variable": "divisor"
    })
    
    # Initialize the intelligent debugger
    Let debugger = IntelligentDebugger.create({
        "analysis_level": "comprehensive",
        "suggestion_mode": "interactive"
    })
    
    # Diagnose the error
    Let diagnosis = debugger.diagnose_error(error_object, {
        "include_context": true,
        "max_suggestions": 3
    })
    
    # Display diagnosis results
    Print("Error diagnosis:")
    Print("Type: " + diagnosis.error_type)
    Print("Root cause: " + diagnosis.root_cause)
    Print("Location: " + diagnosis.location)
    
    Print("\nSuggested fixes:")
    For suggestion in diagnosis.suggestions:
        Print("- " + suggestion.description)
        Print("  Confidence: " + suggestion.confidence)
        Print("  Code: " + suggestion.code_snippet)
    
    # Apply first suggestion if confidence is high
    If diagnosis.suggestions.length > 0 && diagnosis.suggestions[0].confidence > 0.8:
        Let result = debugger.apply_fix(diagnosis.suggestions[0], {
            "create_backup": true,
            "add_comment": true
        })
        
        Print("\nFix applied: " + result.success)
        If result.success:
            Print("Modified file: " + result.file_path)
    
    Return diagnosis

# Example 2: Using semantic breakpoints
Process called "semantic_breakpoint_demo":
    # Initialize debugger
    Let debugger = IntelligentDebugger.create()
    
    # Create different types of semantic breakpoints
    Let value_breakpoint = debugger.create_semantic_breakpoint({
        "type": "value_condition",
        "target": "cart.total_price",
        "condition": "< 0",
        "description": "Detect negative cart total",
        "capture_context": true
    })
    
    Let pattern_breakpoint = debugger.create_semantic_breakpoint({
        "type": "pattern_match",
        "pattern": "database access without validation",
        "capture_stack_trace": true
    })
    
    Let performance_breakpoint = debugger.create_semantic_breakpoint({
        "type": "performance_anomaly",
        "target": "order_processing()",
        "threshold": "500ms",
        "baseline": "average"
    })
    
    # Activate all breakpoints
    debugger.activate_breakpoints()
    
    # Simulate program execution that would trigger breakpoints
    Print("Running program with semantic breakpoints active...")
    Let result = simulate_execution_with_breakpoints()
    
    # Check if any breakpoints were triggered
    For trigger in result.triggered_breakpoints:
        Print("\nBreakpoint triggered: " + trigger.breakpoint_type)
        Print("Description: " + trigger.description)
        Print("Location: " + trigger.location)
        
        If trigger.has_context:
            Print("\nContext captured:")
            For var_name in trigger.context.keys():
                Print("- " + var_name + ": " + trigger.context[var_name])
    
    Return result

# Example 3: Root cause analysis
Process called "analyze_complex_error":
    # Load a more complex error for demonstration
    Let complex_error = load_sample_error("database_timeout")
    
    # Initialize debugger
    Let debugger = IntelligentDebugger.create()
    
    # Perform root cause analysis
    Print("Analyzing root cause of database timeout error...")
    Let root_cause_analysis = debugger.analyze_root_cause(complex_error, {
        "max_depth": 10,
        "include_external_factors": true,
        "analyze_data_flow": true,
        "analyze_control_flow": true
    })
    
    # Display root cause analysis results
    Print("Root cause analysis complete")
    Print("Primary cause: " + root_cause_analysis.primary_cause)
    Print("Confidence: " + root_cause_analysis.confidence)
    
    Print("\nCausal chain:")
    For step in root_cause_analysis.causal_chain:
        Print(step.sequence + ". " + step.description)
        Print("   Location: " + step.location)
        Print("   Relevance: " + step.relevance_score)
    
    Print("\nRecommended resolution:")
    Print(root_cause_analysis.recommended_resolution)
    
    # Generate fix for the identified root cause
    If root_cause_analysis.can_generate_fix:
        Let fix = root_cause_analysis.generate_fix()
        Print("\nGenerated fix for root cause:")
        Print(fix.description)
        Print("File: " + fix.file)
        Print("Code:\n" + fix.code)
    
    Return root_cause_analysis

# Example 4: Time-travel debugging
Process called "time_travel_debugging":
    # Initialize debugger with time-travel capability
    Let debugger = IntelligentDebugger.create()
    
    # Enable time-travel debugging
    debugger.enable_time_travel({
        "memory_limit": "1GB",
        "capture_interval": "statement",
        "auto_snapshot_frequency": 500
    })
    
    # Run function with time-travel recording
    Print("Running calculation with time-travel debugging...")
    Let result = calculate_compound_interest(1000, 0.05, 5, "monthly")
    
    # Navigate execution history
    Print("Time travel navigation:")
    
    # Step back through execution history
    Print("\nStepping backward through history:")
    For i in range(0, 3):
        Let prev_state = debugger.go_to_previous_state()
        Print("State " + prev_state.id + ":")
        Print("- Line: " + prev_state.line + " in " + prev_state.file)
        Print("- Variables:")
        For var_name in prev_state.variables.keys():
            Print("  " + var_name + ": " + prev_state.variables[var_name])
    
    # Find specific state in history
    Print("\nFinding state where interest was negative:")
    Let target_state = debugger.find_state_where({
        "condition": "interest < 0",
        "search_direction": "backward"
    })
    
    If target_state:
        Print("Found problematic state!")
        Print("State ID: " + target_state.id)
        Print("Line: " + target_state.line + " in " + target_state.file)
        Print("Variables at this point:")
        For var_name in target_state.variables.keys():
            Print("- " + var_name + ": " + target_state.variables[var_name])
        
        # Analyze what led to this state
        Let explanation = debugger.explain_state_transition(target_state.id, {
            "detail_level": "detailed"
        })
        
        Print("\nExplanation of how we reached this state:")
        Print(explanation)
    Else:
        Print("No state found where interest was negative")
    
    # Disable time-travel to free resources
    debugger.disable_time_travel()
    
    Return {
        "calculation_result": result,
        "problematic_state": target_state
    }

# Example 5: Execution flow visualization
Process called "visualize_execution_flow":
    # Initialize debugger
    Let debugger = IntelligentDebugger.create()
    
    # Start recording program execution
    debugger.start_execution_recording({
        "max_depth": 10,
        "include_variables": true,
        "include_return_values": true
    })
    
    # Run complex process to analyze
    Let process_result = process_customer_order("ORD-12345")
    
    # Stop recording
    Let execution_data = debugger.stop_execution_recording()
    
    # Generate execution flow visualization
    Print("Generating execution flow visualization...")
    Let visualization = debugger.visualize_execution_flow(execution_data, {
        "format": "interactive",
        "highlight_hotspots": true,
        "group_similar_calls": true,
        "max_nodes": 50
    })
    
    # Display information about the visualization
    Print("Visualization generated:")
    Print("Total nodes: " + visualization.stats.total_nodes)
    Print("Max depth: " + visualization.stats.max_depth)
    Print("Execution time: " + visualization.stats.total_time + "ms")
    Print("Hotspots identified: " + visualization.stats.hotspots.length)
    
    # Save visualization to file
    Let saved_path = visualization.save("./debug_output/order_processing_flow.html")
    Print("Visualization saved to: " + saved_path)
    
    # Highlight critical path
    Let critical_path = visualization.highlight_critical_path()
    Print("\nCritical path in execution:")
    For node in critical_path:
        Print("- " + node.function + " (" + node.time + "ms)")
    
    Return {
        "visualization": visualization,
        "process_result": process_result,
        "execution_data": execution_data
    }

# Example 6: Log analysis with AI
Process called "analyze_application_logs":
    # Initialize debugger
    Let debugger = IntelligentDebugger.create()
    
    # Analyze application logs
    Print("Analyzing application logs...")
    Let log_analysis = debugger.analyze_logs("./logs/application.log", {
        "time_range": "last_24_hours",
        "detect_anomalies": true,
        "identify_patterns": true,
        "correlate_errors": true,
        "severity_threshold": "warning"
    })
    
    # Display log analysis results
    Print("Log Analysis Results:")
    Print("Total entries analyzed: " + log_analysis.total_entries)
    Print("Warning events: " + log_analysis.warning_count)
    Print("Error events: " + log_analysis.error_count)
    Print("Anomalies detected: " + log_analysis.anomalies.length)
    Print("Patterns identified: " + log_analysis.patterns.length)
    
    # Examine top anomalies
    If log_analysis.anomalies.length > 0:
        Print("\nTop Anomalies:")
        For anomaly in log_analysis.anomalies.top(3):
            Print("- " + anomaly.description)
            Print("  Severity: " + anomaly.severity)
            Print("  First occurrence: " + anomaly.first_occurrence)
            Print("  Frequency: " + anomaly.frequency)
            Print("  Possible causes: " + anomaly.possible_causes.join(", "))
    
    # Generate remediation plan
    Let remediation_plan = log_analysis.generate_remediation_plan()
    Print("\nRemediation Plan:")
    For step in remediation_plan.steps:
        Print(step.order + ". " + step.description)
    
    Return log_analysis

# Example 7: Collaborative debugging
Process called "collaborative_debugging_session":
    # Initialize debugger
    Let debugger = IntelligentDebugger.create()
    
    # Simulate an error for demonstration
    Let error_data = simulate_authentication_error()
    
    # Create a collaborative debugging session
    Print("Creating collaborative debugging session...")
    Let session = debugger.create_collaborative_session({
        "name": "Authentication System Bug",
        "description": "Investigating intermittent login failures",
        "permission": "team_only",
        "expires_in": "48h"
    })
    
    # Add artifacts to the session
    session.add_error_log(error_data)
    session.add_code_snapshot("./src/auth/authenticator.runa")
    session.add_note("The issue happens only for users with special characters in username")
    
    # Diagnose the error
    Let diagnosis = debugger.diagnose_error(error_data)
    session.add_error_diagnosis(diagnosis)
    
    # Perform root cause analysis
    Let root_cause = debugger.analyze_root_cause(error_data)
    session.add_root_cause_analysis(root_cause)
    
    # Generate shareable link
    Let share_link = session.generate_link()
    Print("Collaborative debugging session created")
    Print("Share link: " + share_link)
    
    # Add findings to the session
    session.add_finding({
        "type": "root_cause",
        "description": "Input validation is not handling non-ASCII characters correctly",
        "evidence": ["error_trace_id:12345", "input_sample:user@例子.com"],
        "proposed_fix": "Update input validation to properly handle Unicode strings"
    })
    
    # Mark issues as resolved (later)
    Print("\nApplying fix and marking as resolved...")
    session.mark_resolved({
        "resolution_type": "fix_applied",
        "fix_description": "Updated input validation to use proper Unicode handling",
        "fixed_by": "developer_id:9876",
        "verified": true
    })
    
    Return {
        "session": session,
        "share_link": share_link
    }

# Example 8: Predictive debugging
Process called "predictive_debugging":
    # Initialize debugger
    Let debugger = IntelligentDebugger.create()
    
    # Run predictive analysis on codebase
    Print("Running predictive analysis on codebase...")
    Let prediction_results = debugger.run_predictive_analysis("./src/", {
        "prediction_types": ["errors", "performance_bottlenecks", "security_vulnerabilities"],
        "confidence_threshold": 0.7,
        "max_predictions": 20
    })
    
    # Display prediction results
    Print("Predictive Analysis Results:")
    Print("Total predictions: " + prediction_results.total)
    
    # Group by category
    Print("\nPredictions by category:")
    For category in prediction_results.categories:
        Print("\n" + category.name + " (" + category.count + "):")
        
        # Show top 2 predictions per category
        For prediction in category.top(2):
            Print("- " + prediction.description)
            Print("  Location: " + prediction.location)
            Print("  Confidence: " + prediction.confidence)
            Print("  Potential impact: " + prediction.impact)
            
            # Show recommended action
            Print("  Recommended action: " + prediction.recommendation)
    
    # Generate remediation plan for high-priority issues
    Print("\nGenerating remediation plan for high-priority issues...")
    Let remediation_plan = prediction_results.generate_remediation_plan({
        "priority_threshold": "high",
        "group_by": "component"
    })
    
    Print("Remediation plan generated with " + remediation_plan.total_steps + " steps")
    Print("Estimated effort: " + remediation_plan.estimated_effort + " hours")
    
    Return prediction_results

# Example 9: Integration with knowledge graph
Process called "knowledge_enhanced_debugging":
    # Import knowledge graph module
    import runa.ai.knowledge_graph
    
    # Create a sample error for demonstration
    Let error_object = create_sample_error("database_connection_failed", {
        "connection_string": "postgres://user:pass@db.example.com:5432/mydb",
        "error_code": "ECONNREFUSED"
    })
    
    # Create a knowledge graph enhanced debugger
    Print("Initializing knowledge-enhanced debugger...")
    Let kg_debugger = IntelligentDebugger.create_with_knowledge_graph({
        "knowledge_graph": {
            "source": "./knowledge/project_knowledge.kg",
            "embedding_model": "runa-code-embedding"
        },
        "reasoning_engine": "semantic"
    })
    
    # Diagnose errors with knowledge graph insights
    Print("Diagnosing error with knowledge graph assistance...")
    Let kg_diagnosis = kg_debugger.diagnose_with_knowledge_graph(error_object, {
        "query_dependencies": true,
        "include_historical_patterns": true,
        "use_similar_cases": true
    })
    
    # Display diagnosis enhanced with knowledge
    Print("Knowledge-Enhanced Diagnosis:")
    Print("Error category: " + kg_diagnosis.error_category)
    Print("Components involved: " + kg_diagnosis.components.join(", "))
    Print("Similar past issues: " + kg_diagnosis.similar_issues.count)
    
    Print("\nDomain-specific insights:")
    For insight in kg_diagnosis.domain_insights:
        Print("- " + insight)
    
    # Query related knowledge for context
    Print("\nQuerying related knowledge...")
    Let context = kg_debugger.query_knowledge_context({
        "error_type": error_object.type,
        "components": kg_diagnosis.components,
        "depth": 2
    })
    
    Print("Knowledge context retrieved:")
    For component in context.components:
        Print("\nComponent: " + component.name)
        Print("Purpose: " + component.purpose)
        Print("Dependencies: " + component.dependencies.join(", "))
        Print("Common issues: " + component.common_issues.join(", "))
    
    # Get fix suggestions based on knowledge
    Print("\nGenerating knowledge-informed fix suggestions...")
    Let fixes = kg_diagnosis.get_contextual_fixes()
    
    For fix in fixes:
        Print("- " + fix.description)
        Print("  Confidence: " + fix.confidence)
        Print("  Based on: " + fix.knowledge_source)
        Print("  Code: " + fix.code)
    
    Return {
        "diagnosis": kg_diagnosis,
        "context": context,
        "fixes": fixes
    }

# Example 10: Intelligent Debugging with LLM assistance
Process called "llm_assisted_debugging":
    # Import LLM module
    import runa.ai.llm
    
    # Create an error with stack trace for demonstration
    Let complex_error = create_complex_error_with_stack()
    
    # Create an LLM-enhanced debugger
    Print("Initializing LLM-enhanced debugger...")
    Let llm_debugger = IntelligentDebugger.create_with_llm({
        "model": "runa-debugging-assistant",
        "temperature": 0.3,
        "use_code_context": true
    })
    
    # Get detailed explanation of the error
    Print("Generating natural language explanation of error...")
    Let explanation = llm_debugger.explain_error(complex_error, {
        "detail_level": "detailed",
        "audience": "developer",
        "include_examples": true
    })
    
    Print("Error explanation:")
    Print(explanation.summary)
    Print("\nDetailed explanation:")
    Print(explanation.detailed)
    
    # Generate multiple potential fixes using LLM
    Print("\nGenerating potential fixes using LLM...")
    Let generated_fixes = llm_debugger.generate_fixes_with_llm(complex_error, {
        "max_solutions": 3,
        "explain_solutions": true,
        "consider_best_practices": true
    })
    
    Print("LLM generated " + generated_fixes.length + " potential fixes")
    
    For i in range(0, generated_fixes.length):
        Let fix = generated_fixes[i]
        Print("\nSolution " + (i+1) + ":")
        Print("Description: " + fix.description)
        Print("Code:")
        Print(fix.code)
        Print("Explanation: " + fix.explanation)
        Print("Pros: " + fix.pros.join(", "))
        Print("Cons: " + fix.cons.join(", "))
    
    # Apply the selected fix
    If generated_fixes.length > 0:
        Print("\nApplying first solution...")
        Let result = llm_debugger.apply_fix(generated_fixes[0], {
            "create_backup": true,
            "add_comment": true
        })
        
        If result.success:
            Print("Fix applied successfully to " + result.file_path)
            
            # Verify fix
            Print("Verifying fix...")
            Let verification = llm_debugger.verify_fix(result.file_path)
            Print("Verification result: " + (verification.success ? "Success" : "Failed"))
            If !verification.success:
                Print("Issues found: " + verification.issues.join(", "))
        Else:
            Print("Failed to apply fix: " + result.error)
    
    Return {
        "explanation": explanation,
        "generated_fixes": generated_fixes
    }

# Example 11: Performance profiling and optimization
Process called "performance_profiling":
    # Initialize debugger
    Let debugger = IntelligentDebugger.create()
    
    # Create a performance profiler
    Print("Creating performance profiler...")
    Let profiler = debugger.create_performance_profiler({
        "profiling_mode": "sampling",
        "sampling_rate": 1000,
        "track_memory": true,
        "track_io": true
    })
    
    # Start profiling
    Print("Starting profiling...")
    profiler.start()
    
    # Execute code to profile
    Print("Executing code to profile...")
    Let result = process_large_dataset("./data/large_dataset.json")
    
    # Stop profiling
    Print("Stopping profiling...")
    Let profile_data = profiler.stop()
    
    # Analyze performance data
    Print("Analyzing performance data...")
    Let perf_analysis = profiler.analyze(profile_data, {
        "focus_areas": ["cpu", "memory", "io"],
        "hotspot_threshold": 0.05,
        "generate_flame_graph": true
    })
    
    # Display performance analysis
    Print("Performance Analysis:")
    Print("Total execution time: " + perf_analysis.total_time + "ms")
    
    Print("\nCPU hotspots:")
    For hotspot in perf_analysis.cpu_hotspots:
        Print("- " + hotspot.function + ": " + hotspot.percentage + "% (" + hotspot.time + "ms)")
        Print("  File: " + hotspot.file + ":" + hotspot.line)
        Print("  Called: " + hotspot.call_count + " times")
    
    Print("\nMemory usage:")
    Print("Peak memory: " + perf_analysis.memory_stats.peak + " MB")
    Print("Memory allocations: " + perf_analysis.memory_stats.total_allocations)
    
    # Get optimization suggestions
    Print("\nGenerating optimization suggestions...")
    Let optimizations = profiler.suggest_optimizations(perf_analysis, {
        "max_suggestions": 3,
        "include_code_changes": true
    })
    
    For suggestion in optimizations:
        Print("\nOptimization suggestion: " + suggestion.description)
        Print("Estimated improvement: " + suggestion.estimated_improvement)
        Print("Confidence: " + suggestion.confidence)
        Print("Implementation:")
        Print(suggestion.implementation)
    
    # Save profiling report
    Let report_path = profiler.save_report("./debug_output/performance_report.html")
    Print("\nPerformance report saved to: " + report_path)
    
    Return {
        "analysis": perf_analysis,
        "optimizations": optimizations,
        "report_path": report_path
    }

# Example 12: Complete debugging workflow
Process called "complete_debugging_workflow":
    # Initialize the intelligent debugging system
    Print("Initializing intelligent debugging system...")
    Let debugger = IntelligentDebugger.create({
        "analysis_level": "comprehensive",
        "context_awareness": true,
        "knowledge_sources": [
            {"type": "code_repository", "path": "./src/"},
            {"type": "documentation", "path": "./docs/"},
            {"type": "error_database", "path": "./error_db.json"}
        ]
    })
    
    # Enable monitoring and tracing
    debugger.enable_monitoring({
        "exception_tracking": true,
        "performance_tracking": true,
        "memory_tracking": true,
        "enable_time_travel": true
    })
    
    # Run application with monitoring
    Print("Running application with monitoring enabled...")
    Let result = execute_with_monitoring("./src/main.runa", {
        "arguments": ["--process", "monthly_reports"],
        "timeout": 300
    })
    
    # Analyze results based on success/failure
    If result.has_errors():
        Print("Errors detected during execution. Starting diagnosis...")
        
        # Diagnose error
        Let diagnosis = debugger.diagnose_error(result.error)
        Print("Error diagnosed: " + diagnosis.error_type)
        Print("Root cause: " + diagnosis.root_cause)
        
        # Perform root cause analysis
        Let root_cause = debugger.analyze_root_cause(result.error)
        Print("Primary cause: " + root_cause.primary_cause)
        
        # Get fix suggestions
        Let fixes = diagnosis.suggestions
        If fixes.length > 0:
            Print("Applying fix with highest confidence...")
            Let fix_result = debugger.apply_fix(fixes[0])
            If fix_result.success:
                Print("Fix applied successfully!")
                
                # Verify the fix
                Let verification = debugger.verify_fix(fix_result.file_path)
                Print("Verification: " + (verification.success ? "Passed" : "Failed"))
            Else:
                Print("Failed to apply fix: " + fix_result.error)
    Else:
        Print("Execution completed without errors. Analyzing performance...")
        
        # Analyze performance
        Let perf_analysis = debugger.analyze_performance(result.performance_data)
        Print("Total execution time: " + perf_analysis.total_time + "ms")
        
        # Check for performance bottlenecks
        If perf_analysis.bottlenecks.length > 0:
            Print("Performance bottlenecks detected!")
            For bottleneck in perf_analysis.bottlenecks:
                Print("- " + bottleneck.description)
                Print("  Impact: " + bottleneck.impact + "% of total time")
        Else:
            Print("No significant performance bottlenecks detected.")
    
    # Generate comprehensive report
    Print("Generating comprehensive debugging report...")
    Let report = debugger.generate_report({
        "include_error_analysis": result.has_errors(),
        "include_performance_analysis": true,
        "include_log_analysis": true,
        "format": "html"
    })
    
    Let report_path = "./debug_output/debug_report.html"
    report.save(report_path)
    Print("Debug report saved to: " + report_path)
    
    # Create collaborative session if issues found
    If result.has_errors() || (result.performance_data && perf_analysis.bottlenecks.length > 0):
        Print("Creating collaborative debugging session...")
        Let session = debugger.create_collaborative_session({
            "name": "Debug Session - " + current_date_time(),
            "description": result.has_errors() 
                ? "Error diagnosis and fixes" 
                : "Performance optimization opportunities"
        })
        
        session.add_report(report)
        Let share_link = session.generate_link()
        Print("Collaborative session created: " + share_link)
        
        Return {
            "success": !result.has_errors(),
            "report_path": report_path,
            "session_link": share_link,
            "diagnosis": result.has_errors() ? diagnosis : null,
            "performance": !result.has_errors() ? perf_analysis : null
        }
    Else:
        Return {
            "success": true,
            "report_path": report_path
        } 